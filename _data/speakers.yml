- title: Chris Fonnesbeck
  name: chris-fonnesbeck
  subtitle: Keynote speaker and PyMC BDFL
  twitter: fonnesbeck
  github: fonnesbeck
  web:
  image: Fonnesbeck.png
  thumbnail: Fonnesbeck.png
  alt: Chris
  topic:
  description: Chris is a Senior Quantitative Analyst in Baseball Operations for the New York Yankees.
    He is interested in computational statistics, machine learning, Bayesian methods, and applied decision analysis.
    He hails from Vancouver, Canada and received his Ph.D. from the University of Georgia.
  proposal_summary:
  discourse_link:
  youtube_link:
  presentation_type: Keynote
  time_zone:
  track: All

- title: Viola Priesemann
  name: viola-priesemann
  subtitle: Keynote speaker
  twitter: violapriesemann
  github: vpriesem
  web: http://www.viola-priesemann.de/
  image: Viola.jpg
  thumbnail: Viola.jpg
  alt: Viola
  topic:
  description: Viola heads a research team at the Max Planck Institute for Dynamics and Self-Organization.
    She investigates the self-organization of spreading dynamics in the brain to understand the emergence of living computation.
    With the outbreak of COVID-19, she adapted these mathematical approaches to infer and predict the spread of SARS-CoV-2, and to investigate mitigation strategies.
    Viola is board member of the Campus Institute for Data Science and Fellow of the Schiemann Kolleg.
  proposal_summary:
  discourse_link:
  youtube_link:
  presentation_type: Keynote
  time_zone:
  track: All

- title: Aki Vehtari
  name: aki-vehtari
  subtitle: Keynote speaker
  twitter: avehtari
  github: avehtari
  web: https://users.aalto.fi/~ave/
  image: Aki_Vehtari_Aalto.jpg
  thumbnail: Aki_Vehtari_Aalto.jpg
#  image: Aki_Large.jpg
#  thumbnail: Aki_Large.jpg
  alt: Aki
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  presentation_type: Keynote
  time_zone:
  track: All

- title: Mo Akhshik
  name: mo-akhshik
  subtitle: Speaker
  twitter: MoAkhshik
  github: makhshik
  web:
  image: mo-akhshik.jpg
  thumbnail: mo-akhshik.jpg
  alt: Mo
  topic: A Novel Bayesian Model to Fit Spectrophotometric Data of Hubble and Spitzer Space Telescopes
  proposal_summary: Understanding how the most massive galaxies rapidly formed and quenched when Universe was only ~3 billion years old is one of the major challenges of extragalactic astronomy. In this talk, I will discuss how to improve our understanding of massive galaxy formation by combining the spectro-photometric observations of the Hubble and Spitzer Space Telescopes for strong gravitationally lensed galaxies. In particular, a multi-level regression model is built that can fit all multi-wavelength data for a range of instruments within a hierarchical Bayesian framework to constrain the properties of the stellar populations. The details of how this model is implemented using PyMC3, as well as the estimates of the posteriors of all parameters of interest and nuisance parameters will be highlighted.
  discourse_link:
  youtube_link:
  description: Mo is a grad student of (astro)physics by day, a matheux and a Bayesian enthusiast all along.
    Broadly interested in cosmology and probability too.
  presentation_type: Talk
  time_zone: Africa/Asia/Europe
  track: Advanced
  keywork: mohik

- title: Alex Andorra
  name: alex-andorra
  subtitle: Speaker
  twitter: alex_andorra
  github: AlexAndorra
  web:
  image: alex.png
  thumbnail: alex.png
  alt: Alex
  topic:
  proposal_summary: Predicting elections in Paris with hierarchical multinomial regression
  discourse_link:
  youtube_link:
  description: By day, Alex is a data scientist trying to implement Bayesian models at the French firm Societe.com.
    By night, he doesn’t (yet) fight crime, but he’s an open-source enthusiast and core contributor to the python packages PyMC and ArviZ.
    Alex is also the creator and host of the only podcast dedicated to Bayesian statistics, “Learning Bayesian Statistics”.
    Every fortnight, he interviews practitioners of all fields about why and how they use Bayesian statistics.
    He also loves Nutella a bit too much, but he doesn’t like talking about it -- he prefers eating it.
  presentation_type: Let's Build a Model
  time_zone: Africa/Asia/Europe
  track: Advanced
  keywork: Alerra

- title: Agustina Arroyuelo
  name: agustina-arroyuelo
  subtitle: Speaker
  twitter:
  github: agustinaarroyuelo
  web:
  image: Agustina_Arroyuelo.jpg
  thumbnail: Agustina_Arroyuelo.jpg
  alt: Agustina
  topic: Studying glycan 3D structures with PyMC3 and ArviZ
  proposal_summary: I will describe how to model glycan torsion angles with PyMC3 and ArviZ.
  discourse_link:
  youtube_link:
  description: Agustina is a PhD student in the field of structural bioinformatics.
  presentation_type: Talk
  time_zone: Americas
  track: Beginner
  keywork: Aguelo

- title: Matthijs Brouns
  name: matthijs-brouns
  subtitle: Speaker
  twitter: MatthijsBrs
  github: mbrouns
  web: https://www.linkedin.com/in/mbrouns/
  image: matthijs-brounds.jpeg
  thumbnail: matthijs-brounds.jpeg
  alt: Matthijs
  topic: Priors of Great Potential - How you can add Fairness Constraints to Models using Priors
  proposal_summary:
  discourse_link:
  youtube_link:
  description: Matthijs spends a fair amount of time contributing to our open scientific computing ecosystem through various means.
    He maintains open source packages (scikit-lego, seers) as well as co-chair the PyData Amsterdam conference and meetup.
    His current work involves training junior data scientists at Xccelerated.io.
  presentation_type: Let's Build a Model
  time_zone:
  track: Advanced
  keywork: Vindam

- title: Dario Caramelli
  name: dario-caramelli
  subtitle: Speaker
  twitter: dariocaramelli
  github:
  web:  http://linkedin.com/in/dario-caramelli-705250150
  image: Dario_Caramelli.jpg
  thumbnail: Dario_Caramelli.jpg
  alt: Dario
  topic: An alcohol? What are the chances! Knowledge-based and probabilistic models in chemistry using PyMC3
  proposal_summary: We have used PyMC3 to formulate an explainable probabilistic model of chemical reactivity. This probabilistic model combines the intuitive concepts of high school chemistry with the computer's ability to store and reason about large datasets. We use our model in the lab, where it guides a robot chemist towards \"interesting\" experiments that might lead to the discovery of new reactions.
  discourse_link:
  youtube_link:
  description: Dario Caramelli is a research associate in the Cronin group at the University of Glasgow.
    His research involves building and programming of autonomous robots for reaction discovery as well as the development of algorithms for chemical space modelling and data processing.
    Dario obtained a Master degree in Organic chemistry in Rome (2015) and a PhD in the Cronin group (2019)."
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Advanced
  keywork: Hesehr

- title: Tushar Chandra
  name: tushar-chandra
  subtitle: Speaker
  twitter: threeshar
  github: tuchandra
  web: https://tusharc.dev
  image: tushar_shandra.jpg
  thumbnail: tushar_shandra.jpg
  alt: Tushar
  topic: Learning Bayesian Statistics with Pokemon GO
  proposal_summary: In the mobile game Pokemon GO, players can rarely encounter \"shiny\" Pokemon. The exact appearance rates are unknown. But by using Bayesian inference and PyMC3, we can model different species' shiny rates. In this beginner-level tutorial, we will introduce fundamental principles at the heart of Bayesian modeling; then we will apply them to develop PyMC3 models that can answer questions about Pokemon GO.
  discourse_link:
  youtube_link:
  description: Tushar is a senior data scientist at Nielsen Global Media in Chicago.
    At Nielsen, he works on developing Bayesian models for next-generation audience measurement.
    He loves cats (living with two, Luna and Ruby), chai, and college football.
    This is his first conference talk!
  presentation_type: Let's Build a Model
  time_zone: Americas
  track: Beginner

- title: Cameron Davidson-Pilon
  name: cameron-davidson-pilon
  subtitle: Speaker
  twitter: cmrn_dp
  github:
  web:
  image: cameron-davidson-pilon.jpg
  thumbnail: cameron-davidson-pilon.jpg
  alt: Cameron
  topic:
  proposal_summary: In this LBAM, we'll introduce the microbiological task of cell counting and understand all the potential sources of error involved. We'll model each source of error probabilistically, introduce priors, and then discuss inference on the posterior. Finally, we'll explore how we can extend our model to use in a calibration curve for other instruments. Only basic probability theory is required for this LBAM.
  discourse_link:
  youtube_link:
  description: Cameron Davidson-Pilon has worked in many areas of applied statistics, from the evolutionary dynamics of genes to modeling of financial prices.
    His contributions to the community include lifelines, an implementation of survival analysis in Python, lifetimes, and Bayesian Methods for Hackers, an open source book & printed book on Bayesian analysis.
    Formally Director of Data Science at Shopify, Cameron is now applying data science to food microbiology.
  presentation_type: Let's Build a Model
  time_zone: Americas
  track: Beginner
  keywork: Camlon

- title: Tim Dodwell
  name: tim-dodwell
  subtitle: Speaker
  twitter: proftimdodwell
  github:
  web: https://www.datacentricengineering.co.uk/team.html
  image: TimDodwell.jpg
  thumbnail: TimDodwell.jpg
  alt: Tim
  topic: The MLDA multilevel sampler in PyMC3
  proposal_summary: This presentation will give you the chance to know more about PyMC3’s new multilevel MCMC sampler, MLDA, and help you use it in practice. MLDA exploits multilevel model hierarchies to improve sampling efficiency compared to standard methods, especially when working with high-dimensional problems where gradients are not available. We will present a step-by-step guide on how to use MLDA within PyMC3, go through its various features and also present some advanced use cases, e.g. employing multilevel PDE-based models written in FEniCS and using adaptive error correction to correct model bias between different levels.
  discourse_link:
  youtube_link:
  description: Prof. Tim Dodwell has a personal chair in Computational Mechanics at the University of Exeter,
    is the Romberg Visiting at Heidelberg in Scientific Computing
    and holds a 5 year Turing AI Fellowship at the Alan Turing Institute where he is also an academic lead.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Advanced
  keywork: Timwell

- title: Allen Downey
  name: allen-downey
  subtitle: Speaker
  twitter: allendowney
  github: AllenDowney
  web: allendowney.com
  image: downey_photo_med.jpg
  thumbnail: downey_photo_med.jpg
  alt: Allen
  topic:
  proposal_summary: Tools like PyMC make it easy to implement probablistic models, but it is still challenging to develop and validate those models.  In this talk, I present an incremental strategy for developing and testing models by alternating between forward and inverse probabilities and between grid algorithms and MCMC.  I'll use Poisson processes as an example, but this strategy applies to other probabilistic models.
  discourse_link:
  youtube_link:
  description: Allen Downey is a professor of Computer Science at Olin College and Visiting Lecturer at Ashesi University in Ghana.
    He is the author of a series of open-source textbooks related to software and data science, including Think Python, Think Bayes, and Think Complexity, which are also published by O’Reilly Media.
    His blog, Probably Overthinking It, features articles on Bayesian probability and statistics.
    He holds a Ph.D. in computer science from U.C. Berkeley, and M.S. and B.S. degrees from MIT.
  presentation_type: Let's Build a Model
  time_zone: Americas
  track: Beginner
  keywork: Allney

- title: Laura Helleckes
  name: laura-helleckes
  subtitle: Speaker
  twitter: laurahelleckes
  github: lhelleckes
  web:
  image: helleckes_07.jpg
  thumbnail: helleckes_07.jpg
  alt: Laura
  topic: "calibr8: Going beyond linear ranges with non-linear calibration curves and multilevel modeling"
  proposal_summary: "You just coded up a beautiful model and dummy prediction looks great. Now comes the data, but wait: the units don't match! And to make matters worse, the correlation between model variable and measurement readout is non-linear and heteroscedastic! Sounds familiar? non-linear calibration to the rescue! With `calibr8`, we present a statistical framework and corresponding open source Python package that solves non-linear calibration and likelihood functions for modeling. From a laboratory automation and systems biology perspective, the advantage of non-linear calibration with `calibr8` is two-fold: For lab scientists doing (high-throughput) experiments, `calibr8` facilitates more intuitive uncertainty quantification and makes every-day data analysis more robust, automatable and Bayesian. From a modeling perspective, non-linear _error models_ are essential components of realistic Bayesian process models, and are key to accurately describe the nastiest step of the data-generating process. In this talk, we will take you step-by-step through the data-generating process of an automated bioassay and demonstrate how its non-linearities are modeled with `calibr8`. We will show how `calibr8` can make your life easier - and of course more Bayesian - even if you don't always go all the way to a process model. Finally, we will show how non-linear error models and multi-level modeling with `PyMC3` enable you to get more information out of heterogeneous regression analyses. Join us for the talk and discussion to learn about building Bayesian models for bioassays and dive into the fascinatingly frightening world of non-linear measurement errors!"
  discourse_link:
  youtube_link:
  description: A biotechnologist by training, Laura transitioned to Data Science in the past years and is now a Bayesian enthusiast.
    In her Master’s thesis, she _actually_ collected the data Michael was using for his fancy Bayesian models.
    During her wet lab experience, Laura gained valuable knowledge on microorganisms and biological processes that she is now applying to implement mechanistic process models.
    Her experimental work also gave her the motivation to focus on lab automation for bioprocess development in her PhD at Forschungszentrum Jülich.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Micege

- title: Michael Johns
  name: michael-johns
  subtitle: Speaker
  twitter:
  github:
  web:
  image: Mjohns.jpeg
  thumbnail: Mjohns.jpeg
  alt: Michael
  topic: A Bayesian Approach to Media Mix Modeling
  proposal_summary: This talk describes how we built a Bayesian Media Mix Model of new customer acquisition using PyMC3. We will explain the statistical structure of the model in detail, with special attention to nonlinear functional transformations, discuss some of the technical challenges we tackled when building it in a Bayesian framework, and touch on how we use it in production to guide our marketing strategy.
  discourse_link:
  youtube_link:
  description: Michael Johns is a data scientist at HelloFresh US.
    His work focuses on building statistical models for business applications,
    such as optimizing marketing strategy, customer acquisition forecasting and customer retention.
  presentation_type: Talk
  time_zone: Americas
  track: Beginner
  keywork: Michns

- title: Rasul Karimov
  name: rasul-karimov
  subtitle: Speaker
  twitter: rkarrimov
  github: rrkarim 
  web:
  image: Rasul_Karimov.jpg
  thumbnail: Rasul_Karimov.jpg
  alt: Rasul
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  description: Just finished Master's degree in Data Science.
    Had a great experience expanding the PyMC4 library during this summer's GSoC.
  presentation_type: Let's Build a Model
  time_zone:
  track: Beginner
  keyword:

- title: Sayam Kumar
  name: sayam-kumar
  subtitle: Speaker
  twitter: sayamkumar753
  github: Sayam753
  web: https://www.codingpaths.com/
  image: Sayam_Kumar.jpg
  thumbnail: Sayam_Kumar.jpg
  alt: Sayam
  topic: Demystifying Variational Inference
  proposal_summary: What will you do if MCMC is taking too long to sample? Also what if the dataset is huge? Is there any other cost-effective method for finding the posterior that can save us and potentially produce similar results? Well, you have come to the right place. In this talk, I will explain the intuition and maths behind Variational Inference, the algorithms capturing the amount of correlation, out of the box implementations that we can use, and ultimately diagnosing the model to fit our use case.
  discourse_link:
  youtube_link:
  description: Sayam Kumar is a Computer Science undergraduate student at IIIT Sri City, India.
    He loves to travel and study maths in his free time. He also finds Bayesian statistics super awesome.
    He was a Google Summer of Code student with NumFOCUS community and contributed towards adding Variational Inference methods to PyMC4.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Saymar

- title: Junpeng Lao
  name: junpeng-lao
  subtitle: Speaker
  twitter: junpenglao
  github:
  web:
  image: junpeng.png
  thumbnail: junpeng.png
  alt: Junpeng
  topic: Partial Missing Multivariate observation and what to do with them
  proposal_summary: Missing value is pretty common in any real world data set. While PyMC3 provides convenient automatic imputation, how do we verify it works, especially dealing with multivariate observation with partially missing value? Come to this tutorial to find out!
  discourse_link:
  youtube_link:
  description: Junpeng Lao is a pymc developer and currently a data scientist at Google.
    He also contribute to Tensorflow Probability and varies other Open source libraries.
  presentation_type: Tutorial
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Junlao

- title: Mikkel Lykkegaard
  name: mikkel-lykkegaard
  subtitle: Speaker
  twitter:
  github:
  web: http://emps.exeter.ac.uk/engineering/staff/ml624
  image: Mikkel_Lykkegaard.JPG
  thumbnail: Mikkel_Lykkegaard.JPG
  alt: Mikkel
  topic: The MLDA multilevel sampler in PyMC3
  proposal_summary: This presentation will give you the chance to know more about PyMC3’s new multilevel MCMC sampler, MLDA, and help you use it in practice. MLDA exploits multilevel model hierarchies to improve sampling efficiency compared to standard methods, especially when working with high-dimensional problems where gradients are not available. We will present a step-by-step guide on how to use MLDA within PyMC3, go through its various features and also present some advanced use cases, e.g. employing multilevel PDE-based models written in FEniCS and using adaptive error correction to correct model bias between different levels.
  discourse_link:
  youtube_link:
  description: Mikkel Lykkegaard is a PhD student with the Data Centric Engineering Group and Centre for Water Systems (CWS) at University of Exeter.
    His research is mainly concerned with Uncertainty Quantification (UQ) for computationally intensive forward models.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Advanced
  keywork: Timwell

- title: Ruben Mak
  name: ruben-mak
  subtitle: Speaker
  twitter: 
  github: rubenmak
  web:
  image: Ruben_Mak.jpg
  thumbnail: Ruben_Mak.jpg
  alt: Ruben
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  description: Back in 2012, Ruben introduced data science at Greenhouse, a digital advertising agency in the Netherlands.
    He is currently principal data scientist and cluster lead.
    He’s given several talks at PyData conferences and is one of the founders of PyData Eindhoven.
  presentation_type: Talk
  time_zone:
  track: Advanced
  keyword:

- title: Osvaldo Martin
  name: osvaldo-martin
  subtitle: Speaker
  twitter: aloctavodia
  github: aloctavodia
  web:
  image: profile_oam.jpg
  thumbnail: profile_oam.jpg
  alt: Osvaldo
  topic: "Sequential Monte Carlo: Introduction and diagnostics"
  proposal_summary: In this talk we will provide a brief introduction to Sequential Monte Carlo (SMC) methods and provide a guide to diagnose posterior samples computed using SMC.
  discourse_link:
  youtube_link:
  description: Osvaldo is a researcher at the National Scientific and Technical Research Council in Argentina
    and is notably the author of the book Bayesian Analysis with Python, whose second edition was published in December 2018.
    He also teaches bioinformatics, data science and Bayesian data analysis, and is a core developer of PyMC3 and ArviZ, and recently started contributing to Bambi.
    Originally a biologist and physicist, Osvaldo trained himself to python and Bayesian methods – and what he's doing with it is pretty amazing!
  presentation_type: Talk
  time_zone: Americas
  track: Advanced
  keywork: Osvtin

- title: Hessam Mehr
  name: hessam-mehr
  subtitle: Speaker
  twitter: hessammehr
  github: hessammehr
  web: https://hessammehr.github.io
  image: Hessam_Mehr.jpg
  thumbnail: Hessam_Mehr.jpg
  alt: Hessam Mehr
  topic: An alcohol? What are the chances! Knowledge-based and probabilistic models in chemistry using PyMC3
  proposal_summary: We have used PyMC3 to formulate an explainable probabilistic model of chemical reactivity. This probabilistic model combines the intuitive concepts of high school chemistry with the computer's ability to store and reason about large datasets. We use our model in the lab, where it guides a robot chemist towards "interesting" experiments that might lead to the discovery of new reactions.
  discourse_link:
  youtube_link:
  description: Hessam Mehr is a research associate in the Cronin group at the University of Glasgow's School of Chemistry.
    He works with an interdisciplinary group of scientists and engineers to build robots and teach them how to do chemistry.
    Since he joined the group in 2018, Hessam's main focus has been the integration of probabilistic reasoning with chemical robotics and discovery.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Advanced
  keywork: Hesehr

- title: Grigorios Mingas
  name: grigorios-mingas
  subtitle: Speaker
  twitter:
  github: gmingas
  web:
  image: GrigoriosMingas_Photo.jpg
  thumbnail: GrigoriosMingas_Photo.jpg
  alt: Grigorios
  topic: The MLDA multilevel sampler in PyMC3
  proposal_summary: This presentation will give you the chance to know more about PyMC3’s new multilevel MCMC sampler, MLDA, and help you use it in practice. MLDA exploits multilevel model hierarchies to improve sampling efficiency compared to standard methods, especially when working with high-dimensional problems where gradients are not available. We will present a step-by-step guide on how to use MLDA within PyMC3, go through its various features and also present some advanced use cases, e.g. employing multilevel PDE-based models written in FEniCS and using adaptive error correction to correct model bias between different levels.
  discourse_link:
  youtube_link:
  description: Dr. Grigorios Mingas is a Senior Research Data Scientist at The Alan Turing Institute.
    He received his PhD from Imperial College London, where he co-designed MCMC algorithms and hardware to accelerate Bayesian inference.
    He has experience in a wide range of projects as a data scientist.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Advanced
  keywork: Timwell

- title: Quan Nguyen
  name: quan-nguyen
  subtitle: Speaker
  twitter:
  github: KrisNguyen135
  web: https://krisnguyen135.github.io/
  image: quan.png
  thumbnail: quan.png
  alt: Quan
  topic:
  proposal_summary: At the heart of any machine learning (ML) problem is the identification of models that explain the data well, where learning about the model parameters, treated as random variables, is integral. Bayes' theorem, and in general Bayesian learning, offers a principled framework to update one's beliefs about an unknown quantity; Bayesian methods therefore play an important role in many aspects of ML. This introductory talk aims to highlight some of the most prominent areas in Bayesian ML from the perspective of statisticians and analysts, drawing parallels between these areas and common problems that Bayesian statisticians work on.
  discourse_link:
  youtube_link:
  description: Quan is a Bayesian statistics enthusiast (and a programmer at heart).
    He is the author of several programming books on Python and scientific programming.
    Quan is currently pursuing a Ph.D. in computer science at Washington University in St. Louis, researching Bayesian methods in machine learning.
  presentation_type: Talk
  time_zone: Americas
  track: Advanced
  keywork: Quayen

- title: Michael Osthege
  name: michael-osthege
  subtitle: Speaker
  twitter: theCake
  github: michaelosthege
  web:
  image: osthege_06.jpg
  thumbnail: osthege_06.jpg
  alt: Michael
  topic: "calibr8: Going beyond linear ranges with non-linear calibration curves and multilevel modeling"
  proposal_summary: "You just coded up a beautiful model and dummy prediction looks great. Now comes the data, but wait: the units don't match! And to make matters worse, the correlation between model variable and measurement readout is non-linear and heteroscedastic! Sounds familiar? non-linear calibration to the rescue! With `calibr8`, we present a statistical framework and corresponding open source Python package that solves non-linear calibration and likelihood functions for modeling. From a laboratory automation and systems biology perspective, the advantage of non-linear calibration with `calibr8` is two-fold: For lab scientists doing (high-throughput) experiments, `calibr8` facilitates more intuitive uncertainty quantification and makes every-day data analysis more robust, automatable and Bayesian. From a modeling perspective, non-linear _error models_ are essential components of realistic Bayesian process models, and are key to accurately describe the nastiest step of the data-generating process. In this talk, we will take you step-by-step through the data-generating process of an automated bioassay and demonstrate how its non-linearities are modeled with `calibr8`. We will show how `calibr8` can make your life easier - and of course more Bayesian - even if you don't always go all the way to a process model. Finally, we will show how non-linear error models and multi-level modeling with `PyMC3` enable you to get more information out of heterogeneous regression analyses. Join us for the talk and discussion to learn about building Bayesian models for bioassays and dive into the fascinatingly frightening world of non-linear measurement errors!"
  discourse_link:
  youtube_link:
  description: Michael Osthege is a biotech Bayesian by choice.
    He likes to work with robots, bacteria and models as much as he loves to work in enthusiastic teams.
    As a PhD student in laboratory automation for bioprocess development at Forschungszentrum Jülich, he writes software to make robots generate his data.
    Since he unit-tests his code, he always blames the robots if the data doesn't agree with his Bayesian models.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Micege


- title: Luciano Paz
  name: luciano-paz
  subtitle: Speaker
  twitter:
  github: lucianopaz
  web: https://lucianopaz.github.io
  image: luciano-paz.png
  thumbnail: luciano-paz.png
  alt: Luciano
  topic: Forward sampling in pymc
  proposal_summary: Pymc is great for infering parameter values in a model given some observations, but sometimes we also want to generate random samples from the model either as predictions given what we already inferred from the observed data, or we just want to generate synthetic data that's compatible with the model we built. These two kinds of sampling are called posterior predictive and prior predictive sampling, and are collectively called forward sampling. Forward sampling can be hard. The typical problems that show up are related to shape mismatches in hierarchical models, latent categorical values that aren't correctly re-sampled or changing the shape of the data between the training and test phases. In this talk I'll talk about how forward sampling is implemented in pymc3 and pymc4, and give some tips on how to deal with the typical problems that show up when we want to generate forward samples.
  discourse_link:
  youtube_link:
  description: I got into Bayesian stats during my PhD in cognitive neuroscience.
    During my postdoc I got more involved with machine learning, and discovered pymc3.
    I became a core contributor of pymc, learnt a lot in the process and made up my mind to pursue a career outside of academia.
    I am now a machine learning engineer at Innova SpA in Italy.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Lucpaz

- title: Pedro German Ramirez
  name: pedro-german-ramirez
  subtitle: Speaker
  twitter:
  github: pgerramirez
  web:
  image: profile_pgr.jpg
  thumbnail: profile_pgr.jpg
  alt: Pedro
  topic: "Sequential Monte Carlo: Introduction and diagnostics"
  proposal_summary: 'Sequential Monte Carlo (also known as particle filters) were initially confined to the so-called "filtering problem" (the sequential analysis of state-space models), but they popularity has been growing in other areas including non-sequential tasks like estimating a single posterior distribution, i.e. the typical task performed by pm.sample(). For such cases SMC samplers has been presented as alternatives to MCMC methods. Some advantages often listed in the literature are: simple way of estimating the marginal likelihood (generally for the purpose of model choice), easier parallelization, easier design of adaptative methods, and ability to deal with multi-modal posteriors.
  The literature usually fails to acknowledge that SMC methods are a less mature alternative when compared to Hamiltonian Monte Carlo methods, such as the nuts sampler in PyMC3, Stan, etc. SMC methods are also the base for the most advanced Approximate Bayesian Computation (ABC) methods, which are also increasingly used to solve complex problems in fields like polulation genetics, systems biology, astronomy among others.
  The literature on SMC and SMC-ABC methods can be puzzling for newcomers as the same methods has more than one name or sometimes different names correspond to the same method or concept. In this talk we will provide a brief introduction to SMC methods specially focused on clarifying the key concepts and terminology necessary to use SMC methods in practice, and then we will focus on how to diagnose SMC, including results from preliminary experiments.'
  discourse_link:
  youtube_link:
  description: In the year 2014 I completed my Bs. in Molecular Biology at the National University of San Luis, Argentina
    and in 2020 I finished my PhD in the Instute of Applied Mathematics (IMASL) while working within the Structural Bioinformatics Group (BIOS).
    My PhD thesis was centered around the use of a statiscal mechanics model to simulate biologically relevant systems of peptide-lipid interactions.
    Currently I'm doing my postdoc alongside Dr. Osvaldo Martin on probabilistic modeling and Sequential Monte Carlo.
  presentation_type: Talk
  time_zone: Americas
  track: Advanced
  keywork: Pedrez

- title: Elizaveta Semenova
  name: elizaveta-semenova
  subtitle: Speaker
  twitter: liza_p_semenova
  github: elizavetasemenova
  web:
  image: Photo_Liza_square.png
  thumbnail: Photo_Liza_square.png
  alt: Elizaveta
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  description: Elizaveta is currently a postdoc in Bayesian Machine Learning at a pharmaceutical company.
    Her interests span Gaussian Processes, Bayesian Neural Networks,
    compartmental models and differential equations with applications in epidemiology and toxicology.
    She is tool agnostic and builds probabilistic models in either Stan, PyMC3 or Turing.
  presentation_type: Lets Build a Model
  time_zone:
  track: Beginner

- title: Ali Akbar Septiandri
  name: ali-akbar-septiandri
  subtitle: Speaker
  twitter: aliakbars
  github:
  web:
  image: ali-akbar-septiandri.jpg
  thumbnail: ali-akbar-septiandri.jpg
  alt: Ali
  topic:
  proposal_summary: My journey in learning (and relearning) Bayesian methods as a computer scientist
  discourse_link:
  youtube_link:
  description: A data scientist and a lecturer.
    Learning/teaching data science, machine learning, and artificial intelligence.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Alidri

- title: Max Sklar
  name: max-sklar
  subtitle: Speaker
  twitter: maxsklar
  github: maxsklar
  web: www.localmaxradio.com
  image: max_sklar.png
  thumbnail: max_sklar.png
  alt: Max
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  description: Max Sklar is a machine learning engineer and a member of the innovation labs team at Foursquare.
    He hosts a weekly podcast called The Local Maximum which covers a broad range of current issues, including a focus on Bayesian Inference.
  presentation_type: Talk
  time_zone: Americas
  track: Beginner
  keyword:

- title: Nicoleta Spinu
  name: nicoleta-spinu
  subtitle: Speaker
  twitter: nicospinu
  github:
  web:
  image: Nicoleta_Spinu.jpg
  thumbnail: Nicoleta_Spinu.jpg
  alt: Nicoleta
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  description: Nicoleta Spînu is a PhD candidate in Computational Toxicology with a background in pharmaceutical sciences
    and regulatory affairs looking to have her own impact on the protection of human health while promoting animal welfare (Replacement, Reduction and Refinement of animal testing; "the 3Rs").
    Research interests include the science of network and causal inference, computational modelling of chemical toxicity, and regulatory toxicology and policy making.
  presentation_type: Talk
  time_zone:
  track: Beginner
  keyword:

- title: Evdoxia Taka
  name: evdoxia-taka
  subtitle: Speaker
  twitter: evdoxiataka
  github: evdoxiataka
  web:
  image: Evdoxia.jpg
  thumbnail: Evdoxia.jpg
  alt: Evdoxia
  topic:
  proposal_summary: "Automatic transformation of Bayesian probabilistic models into interactive visualisations: models expressed in a probabilistic programming language are translated automatically into interactive multiverse diagrams, a graphical representation of the model’s structure at varying levels of granularity, with seamless integration of uncertainty visualisation. A concrete implementation in Python that translates probabilistic programs to interactive multiverse diagrams will be presented and illustrated by examples for a variety of Bayesian probabilistic models."
  discourse_link:
  youtube_link:
  description: Evdoxia is a PhD student at the School of Computing Science of University of Glasgow since 2019.
    Her research focuses on the creation of novel representations of probabilistic models that incorporate animation and interaction for a more intuitive communication of the uncertainty in the variables of probabilistic models.
    She became a Python and Bayesian enthusiast ever since she started her PhD and she got a foot in the door of a whole new-to-her, but very charming world.
    Evdoxia completed her undergraduate and master studies in the Aristotle University of Thessaloniki, Greece as Electrical and Computer Engineer.
    She worked as a Research Assistant at the Centre for Research & Technology Hellas in Thessaloniki contributing to various national- and EU-funded research projects in areas such as computer vision, 3D reconstruction and simulation, machine learning.
    She has also worked as a Research Database Engineer for the HCV Research UK project at the Centre for Virus Research of the University of Glasgow.
  presentation_type: Talk
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Evdaka

- title: Vincent D. Warmerdam
  name: vincent-warmerdam
  subtitle: Speaker
  twitter: fishnets88
  github: koaning
  web: koaning.io/calmcode.io
  image: vincent-warmerdam.jpeg
  thumbnail: vincent-warmerdam.jpeg
  alt: Vincent
  topic:
  proposal_summary: Priors of Great Potential - How you can add Fairness Constraints to Models using Priors.
  discourse_link:
  youtube_link:
  description: Vincent likes to spend his days debunking hype in ML.
    He started a few open source packages (whatlies, scikit-lego, clumper and evol) and is also known as co-founding chair of PyData Amsterdam.
    He currently works at Rasa as a Research Advocate where he tries to make NLP algorithms more accessible.
  presentation_type: Let's Build a Model
  time_zone: Asia/Africa/Europe
  track: Advanced
  keywork: Vindam

- title: Zhenyu Wang
  name: zhenyu-wang
  subtitle: Speaker
  twitter:
  github:
  web:
  image: ZWang.jpg
  thumbnail: ZWang.jpg
  alt: Zhenyu
  topic: A Bayesian Approach to Media Mix Modeling
  proposal_summary: This talk describes how we built a Bayesian Media Mix Model of new customer acquisition using PyMC3. We will explain the statistical structure of the model in detail, with special attention to nonlinear functional transformations, discuss some of the technical challenges we tackled when building it in a Bayesian framework, and touch on how we use it in production to guide our marketing strategy.
  discourse_link:
  youtube_link:
  description: Zhenyu Wang is a Senior Business Intelligence Analyst at HelloFresh International.
    He works on developing and implementing methods to measure the effectiveness of advertising campaigns using analytic and statistical methods.
  presentation_type: Talk
  time_zone: Americas
  track: Beginner
  keywork: Zheang

- title: Thomas Wiecki
  name: thomas-wiecki
  subtitle: Speaker
  twitter: twiecki
  github: twiecki
  web:
  image: twiecki.jpg
  thumbnail: twiecki.jpg
  alt: Thomas
  topic:
  proposal_summary: In this tutorial we will build a COVID-19 model from scratch.
  discourse_link:
  youtube_link:
  description: Thomas is the founder of PyMC Labs, a Bayesian consulting firm.
  presentation_type: Let's Build a Model
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Thocki

- title: Ivan Yashchuk
  name: ivan-yashchuk
  subtitle: Speaker
  twitter:
  github:
  web:
  image: Ivan_Yashchuk.jpg
  thumbnail: Ivan_Yashchuk.jpg
  alt: Ivan
  topic:
  proposal_summary:
  discourse_link:
  youtube_link:
  description: van Yashchuk has 3 years’ experience in computational mechanics
    and scientific computing with occasional contributions to OSS projects.
    He received his M.Sc. in Computational Mechanics from Aalto University, Finland
    and is currently doing PhD research in Probabilistic Machine Learning group at Aalto.
  presentation_type: Tutorial
  time_zone:
  track: Advanced
  keyword:

- title: Rob Zinkov
  name: rob-zinkov
  subtitle: Speaker
  twitter: zaxtax
  github: zaxtax
  web: https://zinkov.com
  image: rob-zinkov.jpeg
  thumbnail: rob-zinkov.jpeg
  alt: Rob
  topic: In this tutorial we will build a COVID-19 model from scratch.
  proposal_summary: Have you ever written a model in PyMC3 and aren't sure if it's any good? In this talk I will show you the many ways you can evaluate how will your model fits your data using PyMC3. Not all these techniques may be applicable for your particular problem but you will definitely walk away with a few new tricks for being confident in the models you fit.
  discourse_link:
  youtube_link:
  description: Rob Zinkov is a PhD student at University of Oxford.
    My research covers how to more efficiently specify and train deep generative models as well as how to more effectively discover a good statistical model for your data.
    Previously I was a research scientist at Indiana University where I was the lead developer of the Hakaru probabilistic programming language.
  presentation_type: Tutorial
  time_zone: Asia/Africa/Europe
  track: Beginner
  keywork: Robkov

- title: Elizaveta Semenova
  name: elizaveta-semenova
  subtitle: Speaker
  twitter: liza_p_semenova
  github: rob-zinkov
  web:
  image: Photo_Liza_square.png
  thumbnail: Photo_Liza_square.png
  alt: Rob
  topic: Building an ordered logistic regression model for toxicity prediction
  proposal_summary: We will build a simple but useful ordered logistic regression model to predict severity of drug-induced liver injury (DILI) from  in vitro data and physicochemical properties of compounds.
  discourse_link:
  youtube_link:
  description: Elizaveta is currently a postdoc in Bayesian Machine Learning at a pharmaceutical
    company. Her interests span Gaussian Processes, Bayesian Neural Networks, compartmental
    models and differential equations with applications in epidemiology and toxicology.
    She is tool agnostic and builds probabilistic models in either Stan, PyMC3 or Turing.
  presentation_type: Lets Build a Model
  time_zone:
  track: Beginner
  keywork: Eliova
# files in css/2017_style/img
